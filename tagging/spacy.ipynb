{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd02f9b1a1b2dc50445377ce6e7454356bd90d47af9cfffa36ecf278b29062a7e05",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2f9b1a1b2dc50445377ce6e7454356bd90d47af9cfffa36ecf278b29062a7e05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Objectives\n",
    "\n",
    "- test different packages and models\n",
    "    - spacy\n",
    "    - tensorflow\n",
    "        - LDA\n",
    "        - BERT\n",
    "        - fasttext"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# data info\n",
    "\n",
    "https://www.kaggle.com/anmolkumar/topic-modeling-for-research-articles-20/tasks?taskId=2470\n",
    "\n",
    "Task Details\n",
    "Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more and more difficult. Tagging or topic modelling provides a way to give clear token of identification to research articles which facilitates recommendation and search process.\n",
    "\n",
    "Earlier on the Independence Day we conducted a Hackathon to predict the topics for each article included in the test set. Continuing with the same problem, In this Live Hackathon we will take one more step ahead and predict the tags associated with the articles.\n",
    "\n",
    "Given the abstracts for a set of research articles, predict the tags for each article included in the test set.\n",
    "Note that a research article can possibly have multiple tags. The research article abstracts are sourced from the following 4 topics:\n",
    "\n",
    "Computer Science\n",
    "Mathematics\n",
    "Physics\n",
    "Statistics\n",
    "List of possible tags are as follows:\n",
    "\n",
    "[Analysis of PDEs, Applications, Artificial Intelligence,Astrophysics of Galaxies, Computation and Language, Computer Vision and Pattern Recognition, Cosmology and Nongalactic Astrophysics, Data Structures and Algorithms, Differential Geometry, Earth and Planetary Astrophysics, Fluid Dynamics,Information Theory, Instrumentation and Methods for Astrophysics, Machine Learning, Materials Science, Methodology, Number Theory, Optimization and Control, Representation Theory, Robotics, Social and Information Networks, Statistics Theory, Strongly Correlated Electrons, Superconductivity, Systems and Control]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import spacy\n",
    "from spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n",
    "from spacy.util import minibatch\n",
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "tags = pd.read_csv('data/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id                                           ABSTRACT  Computer Science  \\\n",
       "0  1824  a ever-growing datasets inside observational a...                 0   \n",
       "1  3094  we propose the framework considering optimal $...                 1   \n",
       "\n",
       "   Mathematics  Physics  Statistics  Analysis of PDEs  Applications  \\\n",
       "0            0        1           0                 0             0   \n",
       "1            0        0           0                 0             0   \n",
       "\n",
       "   Artificial Intelligence  Astrophysics of Galaxies  ...  Methodology  \\\n",
       "0                        0                         0  ...            0   \n",
       "1                        0                         0  ...            0   \n",
       "\n",
       "   Number Theory  Optimization and Control  Representation Theory  Robotics  \\\n",
       "0              0                         0                      0         0   \n",
       "1              0                         0                      0         0   \n",
       "\n",
       "   Social and Information Networks  Statistics Theory  \\\n",
       "0                                0                  0   \n",
       "1                                0                  0   \n",
       "\n",
       "   Strongly Correlated Electrons  Superconductivity  Systems and Control  \n",
       "0                              0                  0                    0  \n",
       "1                              0                  0                    0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ABSTRACT</th>\n      <th>Computer Science</th>\n      <th>Mathematics</th>\n      <th>Physics</th>\n      <th>Statistics</th>\n      <th>Analysis of PDEs</th>\n      <th>Applications</th>\n      <th>Artificial Intelligence</th>\n      <th>Astrophysics of Galaxies</th>\n      <th>...</th>\n      <th>Methodology</th>\n      <th>Number Theory</th>\n      <th>Optimization and Control</th>\n      <th>Representation Theory</th>\n      <th>Robotics</th>\n      <th>Social and Information Networks</th>\n      <th>Statistics Theory</th>\n      <th>Strongly Correlated Electrons</th>\n      <th>Superconductivity</th>\n      <th>Systems and Control</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1824</td>\n      <td>a ever-growing datasets inside observational a...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3094</td>\n      <td>we propose the framework considering optimal $...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "source": [
    "- input abstract\n",
    "- output a representation of the tags, could be multiple"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy\n",
    "# https://www.kaggle.com/matleonard/text-classification # all changed in spacy 3.0\n",
    "# https://spacy.io/api/textcategorizer\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "config = {\n",
    "   \"threshold\": 0.5,\n",
    "   \"model\": DEFAULT_MULTI_TEXTCAT_MODEL,\n",
    "}\n",
    "\n",
    "textcat = nlp.add_pipe(\n",
    "              \"textcat_multilabel\",\n",
    "              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all tags\n",
    "for tag in np.ravel(tags.values):\n",
    "    textcat.add_label(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Analysis of PDEs',\n",
       " 'Applications',\n",
       " 'Artificial Intelligence',\n",
       " 'Astrophysics of Galaxies',\n",
       " 'Computation and Language',\n",
       " 'Computer Vision and Pattern Recognition',\n",
       " 'Cosmology and Nongalactic Astrophysics',\n",
       " 'Data Structures and Algorithms',\n",
       " 'Differential Geometry',\n",
       " 'Earth and Planetary Astrophysics',\n",
       " 'Fluid Dynamics',\n",
       " 'Information Theory',\n",
       " 'Instrumentation and Methods for Astrophysics',\n",
       " 'Machine Learning',\n",
       " 'Materials Science',\n",
       " 'Methodology',\n",
       " 'Number Theory',\n",
       " 'Optimization and Control',\n",
       " 'Representation Theory',\n",
       " 'Robotics',\n",
       " 'Social and Information Networks',\n",
       " 'Statistics Theory',\n",
       " 'Strongly Correlated Electrons',\n",
       " 'Superconductivity',\n",
       " 'Systems and Control')"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "textcat.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "\n",
    "def process_text(df, tags):\n",
    "    texts = df.ABSTRACT\n",
    "\n",
    "    labels = []\n",
    "    for row in range(len(df)):\n",
    "        label_dict = dict()\n",
    "        for tag in tags:\n",
    "            label_dict[tag] = df.loc[row,tag] == 1\n",
    "        labels += [{'cats': label_dict}]\n",
    "    \n",
    "    return texts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        a ever-growing datasets inside observational a...\n",
       "1        we propose the framework considering optimal $...\n",
       "2        nanostructures with open shell transition meta...\n",
       "3        stars are self-gravitating fluids inside which...\n",
       "4        deep neural perception and control networks ar...\n",
       "                               ...                        \n",
       "13999    a methodology of automatic detection of a even...\n",
       "14000    we consider a case inside which the robot has ...\n",
       "14001    despite being usually considered two competing...\n",
       "14002    we present the framework and its implementatio...\n",
       "14003    here we report small-angle neutron scattering ...\n",
       "Name: ABSTRACT, Length: 14004, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "process_text(train, textcat.labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(*process_text(train, textcat.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(\"we propose the framework considering optimal $t$-matchings excluding a prescribed $t$-factors inside bipartite graphs. a proposed framework was the generalization of a nonbipartite matching problem and includes several problems, such as a triangle-free $2$-matching, square-free $2$-matching, even factor, and arborescence problems. inside this paper, we demonstrate the unified understanding of these problems by commonly extending previous important results. we solve our problem under the reasonable assumption, which was sufficiently broad to include a specific problems listed above. we first present the min-max theorem and the combinatorial algorithm considering a unweighted version. we then provide the linear programming formulation with dual integrality and the primal-dual algorithm considering a weighted version. the key ingredient of a proposed algorithm was the technique to shrink forbidden structures, which corresponds to a techniques of shrinking odd cycles, triangles, squares, and directed cycles inside edmonds' blossom algorithm, the triangle-free $2$-matching algorithm, the square-free $2$-matching algorithm, and an arborescence algorithm, respectively.\",\n",
       " {'cats': {'Analysis of PDEs': False,\n",
       "   'Applications': False,\n",
       "   'Artificial Intelligence': False,\n",
       "   'Astrophysics of Galaxies': False,\n",
       "   'Computation and Language': False,\n",
       "   'Computer Vision and Pattern Recognition': False,\n",
       "   'Cosmology and Nongalactic Astrophysics': False,\n",
       "   'Data Structures and Algorithms': True,\n",
       "   'Differential Geometry': False,\n",
       "   'Earth and Planetary Astrophysics': False,\n",
       "   'Fluid Dynamics': False,\n",
       "   'Information Theory': False,\n",
       "   'Instrumentation and Methods for Astrophysics': False,\n",
       "   'Machine Learning': False,\n",
       "   'Materials Science': False,\n",
       "   'Methodology': False,\n",
       "   'Number Theory': False,\n",
       "   'Optimization and Control': False,\n",
       "   'Representation Theory': False,\n",
       "   'Robotics': False,\n",
       "   'Social and Information Networks': False,\n",
       "   'Statistics Theory': False,\n",
       "   'Strongly Correlated Electrons': False,\n",
       "   'Superconductivity': False,\n",
       "   'Systems and Control': False}})"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_data, open('data/spacy_text_label.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'textcat_multilabel': 22.6571195081342}\n",
      "{'textcat_multilabel': 36.55466588283889}\n",
      "{'textcat_multilabel': 46.095829123980366}\n",
      "{'textcat_multilabel': 52.780450004240265}\n",
      "{'textcat_multilabel': 57.51071749042603}\n",
      "{'textcat_multilabel': 60.97146983833227}\n",
      "{'textcat_multilabel': 63.68135900271591}\n",
      "{'textcat_multilabel': 65.80210949639513}\n",
      "{'textcat_multilabel': 67.48517272951358}\n",
      "{'textcat_multilabel': 69.00130326519229}\n"
     ]
    }
   ],
   "source": [
    "# training a text categorizer model\n",
    "# changed based on https://spacy.io/usage/v3#migrating\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "\n",
    "examples = []\n",
    "\n",
    "for text, labels in train_data:\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), labels))\n",
    "nlp.initialize(lambda: examples)\n",
    "\n",
    "for epoch in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Create the batch generator with batch size = 8\n",
    "    batches = minibatch(\n",
    "        examples, size=8)\n",
    "    # Iterate through minibatches\n",
    "    for batch in batches:\n",
    "        nlp.update(batch)\n",
    "    print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('model/spacy_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "docs = [nlp.tokenizer(text) for text in train.ABSTRACT.values]\n",
    "\n",
    "textcat = nlp.get_pipe('textcat_multilabel')\n",
    "scores = textcat.predict(docs)\n",
    "\n",
    "predicted = (scores > .5).astype(int)\n",
    "true = train[[*textcat.labels]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(14004, 25)"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9977606398171951"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "(predicted == true).sum() / (true.shape[0] * true.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "test = pd.read_csv('data/test.csv')\n",
    "docs = [nlp.tokenizer(text) for text in test.ABSTRACT.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat = nlp.get_pipe('textcat_multilabel')\n",
    "scores = textcat.predict(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/submission.csv')\n",
    "submission.iloc[:,1:] = (scores > .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Analysis of PDEs                                 245\n",
       "Applications                                     222\n",
       "Artificial Intelligence                          464\n",
       "Astrophysics of Galaxies                         190\n",
       "Computation and Language                         264\n",
       "Computer Vision and Pattern Recognition          294\n",
       "Cosmology and Nongalactic Astrophysics           257\n",
       "Data Structures and Algorithms                   144\n",
       "Differential Geometry                            237\n",
       "Earth and Planetary Astrophysics                 194\n",
       "Fluid Dynamics                                   145\n",
       "Information Theory                                72\n",
       "Instrumentation and Methods for Astrophysics     219\n",
       "Machine Learning                                1376\n",
       "Materials Science                                283\n",
       "Methodology                                      232\n",
       "Number Theory                                    153\n",
       "Optimization and Control                         112\n",
       "Representation Theory                            148\n",
       "Robotics                                         443\n",
       "Social and Information Networks                  259\n",
       "Statistics Theory                                148\n",
       "Strongly Correlated Electrons                    336\n",
       "Superconductivity                                201\n",
       "Systems and Control                              178\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "submission.iloc[:,1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/submission_spacy_simple.csv', index=False)"
   ]
  }
 ]
}